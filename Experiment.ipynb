{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e630f0-1474-431d-8c48-4c8700faca93",
   "metadata": {},
   "source": [
    "## Transweather model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb23a4b0-8824-4eeb-ab77-b64d521e58c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type (var_name))                            Input Shape          Output Shape         Param #\n",
       "==============================================================================================================\n",
       "Transweather (Transweather)                        [1, 3, 256, 256]     [1, 3, 256, 256]     --\n",
       "├─Tenc (Tenc)                                      [1, 3, 256, 256]     [1, 64, 64, 64]      296,448\n",
       "│    └─OverlapPatchEmbed (patch_embed1)            [1, 3, 256, 256]     [1, 4096, 64]        --\n",
       "│    │    └─Conv2d (proj)                          [1, 3, 256, 256]     [1, 64, 64, 64]      9,472\n",
       "│    │    └─LayerNorm (norm)                       [1, 4096, 64]        [1, 4096, 64]        128\n",
       "│    └─OverlapPatchEmbed (mini_patch_embed1)       [1, 64, 64, 64]      [1, 1024, 128]       --\n",
       "│    │    └─Conv2d (proj)                          [1, 64, 64, 64]      [1, 128, 32, 32]     73,856\n",
       "│    │    └─LayerNorm (norm)                       [1, 1024, 128]       [1, 1024, 128]       256\n",
       "│    └─ModuleList (block1)                         --                   --                   --\n",
       "│    │    └─Block (0)                              [1, 4096, 64]        [1, 4096, 64]        100,480\n",
       "│    │    └─Block (1)                              [1, 4096, 64]        [1, 4096, 64]        100,480\n",
       "│    └─LayerNorm (norm1)                           [1, 4096, 64]        [1, 4096, 64]        128\n",
       "│    └─ModuleList (patch_block1)                   --                   --                   --\n",
       "│    │    └─Block (0)                              [1, 1024, 128]       [1, 1024, 128]       397,568\n",
       "│    └─LayerNorm (pnorm1)                          [1, 1024, 128]       [1, 1024, 128]       256\n",
       "│    └─OverlapPatchEmbed (patch_embed2)            [1, 64, 64, 64]      [1, 1024, 128]       --\n",
       "│    │    └─Conv2d (proj)                          [1, 64, 64, 64]      [1, 128, 32, 32]     73,856\n",
       "│    │    └─LayerNorm (norm)                       [1, 1024, 128]       [1, 1024, 128]       256\n",
       "│    └─OverlapPatchEmbed (mini_patch_embed2)       [1, 128, 32, 32]     [1, 256, 320]        --\n",
       "│    │    └─Conv2d (proj)                          [1, 128, 32, 32]     [1, 320, 16, 16]     368,960\n",
       "│    │    └─LayerNorm (norm)                       [1, 256, 320]        [1, 256, 320]        640\n",
       "│    └─ModuleList (block2)                         --                   --                   --\n",
       "│    │    └─Block (0)                              [1, 1024, 128]       [1, 1024, 128]       200,960\n",
       "│    │    └─Block (1)                              [1, 1024, 128]       [1, 1024, 128]       200,960\n",
       "│    └─LayerNorm (norm2)                           [1, 1024, 128]       [1, 1024, 128]       256\n",
       "│    └─ModuleList (patch_block2)                   --                   --                   --\n",
       "│    │    └─Block (0)                              [1, 256, 320]        [1, 256, 320]        1,239,680\n",
       "│    └─LayerNorm (pnorm2)                          [1, 256, 320]        [1, 256, 320]        640\n",
       "│    └─OverlapPatchEmbed (patch_embed3)            [1, 128, 32, 32]     [1, 256, 320]        --\n",
       "│    │    └─Conv2d (proj)                          [1, 128, 32, 32]     [1, 320, 16, 16]     368,960\n",
       "│    │    └─LayerNorm (norm)                       [1, 256, 320]        [1, 256, 320]        640\n",
       "│    └─OverlapPatchEmbed (mini_patch_embed3)       [1, 320, 16, 16]     [1, 64, 512]         --\n",
       "│    │    └─Conv2d (proj)                          [1, 320, 16, 16]     [1, 512, 8, 8]       1,475,072\n",
       "│    │    └─LayerNorm (norm)                       [1, 64, 512]         [1, 64, 512]         1,024\n",
       "│    └─ModuleList (block3)                         --                   --                   --\n",
       "│    │    └─Block (0)                              [1, 256, 320]        [1, 256, 320]        1,239,680\n",
       "│    │    └─Block (1)                              [1, 256, 320]        [1, 256, 320]        1,239,680\n",
       "│    └─LayerNorm (norm3)                           [1, 256, 320]        [1, 256, 320]        640\n",
       "│    └─ModuleList (patch_block3)                   --                   --                   --\n",
       "│    │    └─Block (0)                              [1, 64, 512]         [1, 64, 512]         3,163,136\n",
       "│    └─LayerNorm (pnorm3)                          [1, 64, 512]         [1, 64, 512]         1,024\n",
       "│    └─OverlapPatchEmbed (patch_embed4)            [1, 320, 16, 16]     [1, 64, 512]         --\n",
       "│    │    └─Conv2d (proj)                          [1, 320, 16, 16]     [1, 512, 8, 8]       1,475,072\n",
       "│    │    └─LayerNorm (norm)                       [1, 64, 512]         [1, 64, 512]         1,024\n",
       "│    └─ModuleList (block4)                         --                   --                   --\n",
       "│    │    └─Block (0)                              [1, 64, 512]         [1, 64, 512]         2,113,024\n",
       "│    │    └─Block (1)                              [1, 64, 512]         [1, 64, 512]         2,113,024\n",
       "│    └─LayerNorm (norm4)                           [1, 64, 512]         [1, 64, 512]         1,024\n",
       "├─Tdec (Tdec)                                      [1, 64, 64, 64]      [1, 512, 4, 4]       --\n",
       "│    └─OverlapPatchEmbed (patch_embed1)            [1, 512, 8, 8]       [1, 16, 512]         --\n",
       "│    │    └─Conv2d (proj)                          [1, 512, 8, 8]       [1, 512, 4, 4]       2,359,808\n",
       "│    │    └─LayerNorm (norm)                       [1, 16, 512]         [1, 16, 512]         1,024\n",
       "│    └─ModuleList (block1)                         --                   --                   --\n",
       "│    │    └─Block_dec (0)                          [1, 16, 512]         [1, 16, 512]         3,197,440\n",
       "│    │    └─Block_dec (1)                          [1, 16, 512]         [1, 16, 512]         3,197,440\n",
       "│    │    └─Block_dec (2)                          [1, 16, 512]         [1, 16, 512]         3,197,440\n",
       "│    └─LayerNorm (norm1)                           [1, 16, 512]         [1, 16, 512]         1,024\n",
       "├─convprojection (convtail)                        [1, 64, 64, 64]      [1, 8, 256, 256]     219\n",
       "│    └─UpsampleConvLayer (convd32x)                [1, 512, 4, 4]       [1, 512, 8, 8]       --\n",
       "│    │    └─ConvTranspose2d (conv2d)               [1, 512, 4, 4]       [1, 512, 8, 8]       4,194,816\n",
       "│    └─UpsampleConvLayer (convd16x)                [1, 512, 8, 8]       [1, 320, 16, 16]     --\n",
       "│    │    └─ConvTranspose2d (conv2d)               [1, 512, 8, 8]       [1, 320, 16, 16]     2,621,760\n",
       "│    └─Sequential (dense_4)                        [1, 320, 16, 16]     [1, 320, 16, 16]     --\n",
       "│    │    └─ResidualBlock_DWConv (0)               [1, 320, 16, 16]     [1, 320, 16, 16]     6,400\n",
       "│    └─UpsampleConvLayer (convd8x)                 [1, 320, 16, 16]     [1, 128, 32, 32]     --\n",
       "│    │    └─ConvTranspose2d (conv2d)               [1, 320, 16, 16]     [1, 128, 32, 32]     655,488\n",
       "│    └─Sequential (dense_3)                        [1, 128, 32, 32]     [1, 128, 32, 32]     --\n",
       "│    │    └─ResidualBlock_DWConv (0)               [1, 128, 32, 32]     [1, 128, 32, 32]     2,560\n",
       "│    └─UpsampleConvLayer (convd4x)                 [1, 128, 32, 32]     [1, 64, 64, 64]      --\n",
       "│    │    └─ConvTranspose2d (conv2d)               [1, 128, 32, 32]     [1, 64, 64, 64]      131,136\n",
       "│    └─Sequential (dense_2)                        [1, 64, 64, 64]      [1, 64, 64, 64]      --\n",
       "│    │    └─ResidualBlock_DWConv (0)               [1, 64, 64, 64]      [1, 64, 64, 64]      1,280\n",
       "│    └─UpsampleConvLayer (convd2x)                 [1, 64, 64, 64]      [1, 16, 128, 128]    --\n",
       "│    │    └─ConvTranspose2d (conv2d)               [1, 64, 64, 64]      [1, 16, 128, 128]    16,400\n",
       "│    └─Sequential (dense_1)                        [1, 16, 128, 128]    [1, 16, 128, 128]    --\n",
       "│    │    └─ResidualBlock_DWConv (0)               [1, 16, 128, 128]    [1, 16, 128, 128]    320\n",
       "│    └─UpsampleConvLayer (convd1x)                 [1, 16, 128, 128]    [1, 8, 256, 256]     --\n",
       "│    │    └─ConvTranspose2d (conv2d)               [1, 16, 128, 128]    [1, 8, 256, 256]     2,056\n",
       "├─ConvLayer (clean)                                [1, 8, 256, 256]     [1, 3, 256, 256]     --\n",
       "│    └─Conv2d (conv2d)                             [1, 8, 256, 256]     [1, 3, 256, 256]     219\n",
       "├─Tanh (active)                                    [1, 3, 256, 256]     [1, 3, 256, 256]     --\n",
       "==============================================================================================================\n",
       "Total params: 35,845,134\n",
       "Trainable params: 35,845,134\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.41\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 142.87\n",
       "Params size (MB): 141.90\n",
       "Estimated Total Size (MB): 285.55\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transweather_model import Transweather\n",
    "from torchinfo import summary\n",
    "from functools import partial\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "model = Transweather()\n",
    "\n",
    "summary(model,\n",
    "        input_size=[1,3,256,256], \n",
    "        verbose=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"],\n",
    "        device = \"cpu\")\n",
    "\n",
    "# see how dataset and dataloaders are formed for training and evaluation\n",
    "# how different image size is handled in training and validation\n",
    "# Note that we find the best model based on validating with raindrop data. \n",
    "\n",
    "# outs is a list where, outputs from encoder stage are appended x1 outputs\n",
    "# how conv tail is working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63abe6a-5c6d-4820-bb68-2bf5ee226c93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## EncoderTransformer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc357b2-8daf-4271-8df2-04fefa24ef0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type (var_name))                       Input Shape          Output Shape         Param #\n",
       "=========================================================================================================\n",
       "EncoderTransformer (EncoderTransformer)       [1, 3, 256, 256]     [1, 64, 64, 64]      296,448\n",
       "├─OverlapPatchEmbed (patch_embed1)            [1, 3, 256, 256]     [1, 4096, 64]        --\n",
       "│    └─Conv2d (proj)                          [1, 3, 256, 256]     [1, 64, 64, 64]      9,472\n",
       "│    └─LayerNorm (norm)                       [1, 4096, 64]        [1, 4096, 64]        128\n",
       "├─OverlapPatchEmbed (mini_patch_embed1)       [1, 64, 64, 64]      [1, 1024, 128]       --\n",
       "│    └─Conv2d (proj)                          [1, 64, 64, 64]      [1, 128, 32, 32]     73,856\n",
       "│    └─LayerNorm (norm)                       [1, 1024, 128]       [1, 1024, 128]       256\n",
       "├─ModuleList (block1)                         --                   --                   --\n",
       "│    └─Block (0)                              [1, 4096, 64]        [1, 4096, 64]        --\n",
       "│    │    └─LayerNorm (norm1)                 [1, 4096, 64]        [1, 4096, 64]        128\n",
       "│    │    └─Attention (attn)                  [1, 4096, 64]        [1, 4096, 64]        82,368\n",
       "│    │    └─Identity (drop_path)              [1, 4096, 64]        [1, 4096, 64]        --\n",
       "│    │    └─LayerNorm (norm2)                 [1, 4096, 64]        [1, 4096, 64]        128\n",
       "│    │    └─Mlp (mlp)                         [1, 4096, 64]        [1, 4096, 64]        17,856\n",
       "│    │    └─Identity (drop_path)              [1, 4096, 64]        [1, 4096, 64]        --\n",
       "│    └─Block (1)                              [1, 4096, 64]        [1, 4096, 64]        --\n",
       "│    │    └─LayerNorm (norm1)                 [1, 4096, 64]        [1, 4096, 64]        128\n",
       "│    │    └─Attention (attn)                  [1, 4096, 64]        [1, 4096, 64]        82,368\n",
       "│    │    └─DropPath (drop_path)              [1, 4096, 64]        [1, 4096, 64]        --\n",
       "│    │    └─LayerNorm (norm2)                 [1, 4096, 64]        [1, 4096, 64]        128\n",
       "│    │    └─Mlp (mlp)                         [1, 4096, 64]        [1, 4096, 64]        17,856\n",
       "│    │    └─DropPath (drop_path)              [1, 4096, 64]        [1, 4096, 64]        --\n",
       "├─LayerNorm (norm1)                           [1, 4096, 64]        [1, 4096, 64]        128\n",
       "├─ModuleList (patch_block1)                   --                   --                   --\n",
       "│    └─Block (0)                              [1, 1024, 128]       [1, 1024, 128]       --\n",
       "│    │    └─LayerNorm (norm1)                 [1, 1024, 128]       [1, 1024, 128]       256\n",
       "│    │    └─Attention (attn)                  [1, 1024, 128]       [1, 1024, 128]       328,576\n",
       "│    │    └─Identity (drop_path)              [1, 1024, 128]       [1, 1024, 128]       --\n",
       "│    │    └─LayerNorm (norm2)                 [1, 1024, 128]       [1, 1024, 128]       256\n",
       "│    │    └─Mlp (mlp)                         [1, 1024, 128]       [1, 1024, 128]       68,480\n",
       "│    │    └─Identity (drop_path)              [1, 1024, 128]       [1, 1024, 128]       --\n",
       "├─LayerNorm (pnorm1)                          [1, 1024, 128]       [1, 1024, 128]       256\n",
       "├─OverlapPatchEmbed (patch_embed2)            [1, 64, 64, 64]      [1, 1024, 128]       --\n",
       "│    └─Conv2d (proj)                          [1, 64, 64, 64]      [1, 128, 32, 32]     73,856\n",
       "│    └─LayerNorm (norm)                       [1, 1024, 128]       [1, 1024, 128]       256\n",
       "├─OverlapPatchEmbed (mini_patch_embed2)       [1, 128, 32, 32]     [1, 256, 320]        --\n",
       "│    └─Conv2d (proj)                          [1, 128, 32, 32]     [1, 320, 16, 16]     368,960\n",
       "│    └─LayerNorm (norm)                       [1, 256, 320]        [1, 256, 320]        640\n",
       "├─ModuleList (block2)                         --                   --                   --\n",
       "│    └─Block (0)                              [1, 1024, 128]       [1, 1024, 128]       --\n",
       "│    │    └─LayerNorm (norm1)                 [1, 1024, 128]       [1, 1024, 128]       256\n",
       "│    │    └─Attention (attn)                  [1, 1024, 128]       [1, 1024, 128]       131,968\n",
       "│    │    └─DropPath (drop_path)              [1, 1024, 128]       [1, 1024, 128]       --\n",
       "│    │    └─LayerNorm (norm2)                 [1, 1024, 128]       [1, 1024, 128]       256\n",
       "│    │    └─Mlp (mlp)                         [1, 1024, 128]       [1, 1024, 128]       68,480\n",
       "│    │    └─DropPath (drop_path)              [1, 1024, 128]       [1, 1024, 128]       --\n",
       "│    └─Block (1)                              [1, 1024, 128]       [1, 1024, 128]       --\n",
       "│    │    └─LayerNorm (norm1)                 [1, 1024, 128]       [1, 1024, 128]       256\n",
       "│    │    └─Attention (attn)                  [1, 1024, 128]       [1, 1024, 128]       131,968\n",
       "│    │    └─DropPath (drop_path)              [1, 1024, 128]       [1, 1024, 128]       --\n",
       "│    │    └─LayerNorm (norm2)                 [1, 1024, 128]       [1, 1024, 128]       256\n",
       "│    │    └─Mlp (mlp)                         [1, 1024, 128]       [1, 1024, 128]       68,480\n",
       "│    │    └─DropPath (drop_path)              [1, 1024, 128]       [1, 1024, 128]       --\n",
       "├─LayerNorm (norm2)                           [1, 1024, 128]       [1, 1024, 128]       256\n",
       "├─ModuleList (patch_block2)                   --                   --                   --\n",
       "│    └─Block (0)                              [1, 256, 320]        [1, 256, 320]        --\n",
       "│    │    └─LayerNorm (norm1)                 [1, 256, 320]        [1, 256, 320]        640\n",
       "│    │    └─Attention (attn)                  [1, 256, 320]        [1, 256, 320]        821,440\n",
       "│    │    └─DropPath (drop_path)              [1, 256, 320]        [1, 256, 320]        --\n",
       "│    │    └─LayerNorm (norm2)                 [1, 256, 320]        [1, 256, 320]        640\n",
       "│    │    └─Mlp (mlp)                         [1, 256, 320]        [1, 256, 320]        416,960\n",
       "│    │    └─DropPath (drop_path)              [1, 256, 320]        [1, 256, 320]        --\n",
       "├─LayerNorm (pnorm2)                          [1, 256, 320]        [1, 256, 320]        640\n",
       "├─OverlapPatchEmbed (patch_embed3)            [1, 128, 32, 32]     [1, 256, 320]        --\n",
       "│    └─Conv2d (proj)                          [1, 128, 32, 32]     [1, 320, 16, 16]     368,960\n",
       "│    └─LayerNorm (norm)                       [1, 256, 320]        [1, 256, 320]        640\n",
       "├─OverlapPatchEmbed (mini_patch_embed3)       [1, 320, 16, 16]     [1, 64, 512]         --\n",
       "│    └─Conv2d (proj)                          [1, 320, 16, 16]     [1, 512, 8, 8]       1,475,072\n",
       "│    └─LayerNorm (norm)                       [1, 64, 512]         [1, 64, 512]         1,024\n",
       "├─ModuleList (block3)                         --                   --                   --\n",
       "│    └─Block (0)                              [1, 256, 320]        [1, 256, 320]        --\n",
       "│    │    └─LayerNorm (norm1)                 [1, 256, 320]        [1, 256, 320]        640\n",
       "│    │    └─Attention (attn)                  [1, 256, 320]        [1, 256, 320]        821,440\n",
       "│    │    └─DropPath (drop_path)              [1, 256, 320]        [1, 256, 320]        --\n",
       "│    │    └─LayerNorm (norm2)                 [1, 256, 320]        [1, 256, 320]        640\n",
       "│    │    └─Mlp (mlp)                         [1, 256, 320]        [1, 256, 320]        416,960\n",
       "│    │    └─DropPath (drop_path)              [1, 256, 320]        [1, 256, 320]        --\n",
       "│    └─Block (1)                              [1, 256, 320]        [1, 256, 320]        --\n",
       "│    │    └─LayerNorm (norm1)                 [1, 256, 320]        [1, 256, 320]        640\n",
       "│    │    └─Attention (attn)                  [1, 256, 320]        [1, 256, 320]        821,440\n",
       "│    │    └─DropPath (drop_path)              [1, 256, 320]        [1, 256, 320]        --\n",
       "│    │    └─LayerNorm (norm2)                 [1, 256, 320]        [1, 256, 320]        640\n",
       "│    │    └─Mlp (mlp)                         [1, 256, 320]        [1, 256, 320]        416,960\n",
       "│    │    └─DropPath (drop_path)              [1, 256, 320]        [1, 256, 320]        --\n",
       "├─LayerNorm (norm3)                           [1, 256, 320]        [1, 256, 320]        640\n",
       "├─ModuleList (patch_block3)                   --                   --                   --\n",
       "│    └─Block (0)                              [1, 64, 512]         [1, 64, 512]         --\n",
       "│    │    └─LayerNorm (norm1)                 [1, 64, 512]         [1, 64, 512]         1,024\n",
       "│    │    └─Attention (attn)                  [1, 64, 512]         [1, 64, 512]         2,100,736\n",
       "│    │    └─DropPath (drop_path)              [1, 64, 512]         [1, 64, 512]         --\n",
       "│    │    └─LayerNorm (norm2)                 [1, 64, 512]         [1, 64, 512]         1,024\n",
       "│    │    └─Mlp (mlp)                         [1, 64, 512]         [1, 64, 512]         1,060,352\n",
       "│    │    └─DropPath (drop_path)              [1, 64, 512]         [1, 64, 512]         --\n",
       "├─LayerNorm (pnorm3)                          [1, 64, 512]         [1, 64, 512]         1,024\n",
       "├─OverlapPatchEmbed (patch_embed4)            [1, 320, 16, 16]     [1, 64, 512]         --\n",
       "│    └─Conv2d (proj)                          [1, 320, 16, 16]     [1, 512, 8, 8]       1,475,072\n",
       "│    └─LayerNorm (norm)                       [1, 64, 512]         [1, 64, 512]         1,024\n",
       "├─ModuleList (block4)                         --                   --                   --\n",
       "│    └─Block (0)                              [1, 64, 512]         [1, 64, 512]         --\n",
       "│    │    └─LayerNorm (norm1)                 [1, 64, 512]         [1, 64, 512]         1,024\n",
       "│    │    └─Attention (attn)                  [1, 64, 512]         [1, 64, 512]         1,050,624\n",
       "│    │    └─DropPath (drop_path)              [1, 64, 512]         [1, 64, 512]         --\n",
       "│    │    └─LayerNorm (norm2)                 [1, 64, 512]         [1, 64, 512]         1,024\n",
       "│    │    └─Mlp (mlp)                         [1, 64, 512]         [1, 64, 512]         1,060,352\n",
       "│    │    └─DropPath (drop_path)              [1, 64, 512]         [1, 64, 512]         --\n",
       "│    └─Block (1)                              [1, 64, 512]         [1, 64, 512]         --\n",
       "│    │    └─LayerNorm (norm1)                 [1, 64, 512]         [1, 64, 512]         1,024\n",
       "│    │    └─Attention (attn)                  [1, 64, 512]         [1, 64, 512]         1,050,624\n",
       "│    │    └─DropPath (drop_path)              [1, 64, 512]         [1, 64, 512]         --\n",
       "│    │    └─LayerNorm (norm2)                 [1, 64, 512]         [1, 64, 512]         1,024\n",
       "│    │    └─Mlp (mlp)                         [1, 64, 512]         [1, 64, 512]         1,060,352\n",
       "│    │    └─DropPath (drop_path)              [1, 64, 512]         [1, 64, 512]         --\n",
       "├─LayerNorm (norm4)                           [1, 64, 512]         [1, 64, 512]         1,024\n",
       "=========================================================================================================\n",
       "Total params: 16,258,304\n",
       "Trainable params: 16,258,304\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 781.74\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 115.61\n",
       "Params size (MB): 63.85\n",
       "Estimated Total Size (MB): 180.24\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transweather_model import EncoderTransformer\n",
    "\n",
    "model = EncoderTransformer(patch_size=4, embed_dims=[64, 128, 320, 512], num_heads=[1, 2, 4, 4], mlp_ratios=[2, 2, 2, 2],\n",
    "            qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), depths=[2, 2, 2, 2], sr_ratios=[4, 2, 2, 1],\n",
    "            drop_rate=0.0, drop_path_rate=0.1)\n",
    "\n",
    "summary(model,\n",
    "        input_size=[1,3,256,256], \n",
    "        verbose=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"],\n",
    "        device = \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e0014-acd9-4522-8424-dddfc5219fbc",
   "metadata": {},
   "source": [
    "##  OverlapPatchEmbed class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91027f65-d316-4ed3-abcf-9a8844fa93c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #\n",
       "====================================================================================================\n",
       "OverlapPatchEmbed                        --                   --                   --\n",
       "├─Conv2d (proj)                          [1, 3, 256, 256]     [1, 64, 64, 64]      9,472\n",
       "├─LayerNorm (norm)                       [1, 4096, 64]        [1, 4096, 64]        128\n",
       "====================================================================================================\n",
       "Total params: 9,600\n",
       "Trainable params: 9,600\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 38.80\n",
       "====================================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 4.19\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 5.02\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transweather_model import OverlapPatchEmbed\n",
    "\n",
    "model = OverlapPatchEmbed(img_size=256, patch_size=7, stride=4, in_chans=3, embed_dim=64)\n",
    "summary(model,\n",
    "        input_size=[1,3,256,256], \n",
    "        verbose=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"],\n",
    "        device = \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b1ec2-1b13-4fbf-aced-2c1ba3e0e98e",
   "metadata": {},
   "source": [
    "## Block class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b109182d-5bf3-4f34-9f89-7ecf39929a79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [LayerNorm: 1, Attention: 1, Linear: 2, Linear: 2, Dropout: 2, Linear: 2, Dropout: 2, Identity: 1, LayerNorm: 1, Linear: 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/transweather/lib/python3.6/site-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transweather/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[0;32m~/TransWeather/transweather_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, H, W)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transweather/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[0;32m~/TransWeather/transweather_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, H, W)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transweather/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[0;32m~/TransWeather/transweather_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, H, W)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: view(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 3",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-737be5ee8fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcol_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mrow_settings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"var_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         device = \"cpu\")\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/transweather/lib/python3.6/site-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     )\n\u001b[1;32m    194\u001b[0m     summary_list = forward_pass(\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_forward_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     )\n\u001b[1;32m    197\u001b[0m     \u001b[0mformatting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFormattingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transweather/lib/python3.6/site-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;34m\"Failed to run torchinfo. See above stack traces for more details. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;34mf\"Executed layers up to: {executed_layers}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         ) from e\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [LayerNorm: 1, Attention: 1, Linear: 2, Linear: 2, Dropout: 2, Linear: 2, Dropout: 2, Identity: 1, LayerNorm: 1, Linear: 2]"
     ]
    }
   ],
   "source": [
    "from transweather_model import Block\n",
    "\n",
    "model = Block(dim=64, num_heads=1, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm, sr_ratio=1) # dim = embedding dimension\n",
    "summary(model,\n",
    "        input_size=[(1,4096, 64), (64, 1), (64,1)], \n",
    "        verbose=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"],\n",
    "        device = \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284104bf-25f5-4840-86d5-3baa97c3989c",
   "metadata": {},
   "source": [
    "## DWConv class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76615e7a-5144-43d2-9be6-bdda016480dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/transweather/lib/python3.6/site-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transweather/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[0;32m~/TransWeather/transweather_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, H, W)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: view(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 3",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-74962b3ed629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcol_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mrow_settings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"var_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         device = \"cpu\")\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/transweather/lib/python3.6/site-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     )\n\u001b[1;32m    194\u001b[0m     summary_list = forward_pass(\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_forward_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     )\n\u001b[1;32m    197\u001b[0m     \u001b[0mformatting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFormattingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transweather/lib/python3.6/site-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;34m\"Failed to run torchinfo. See above stack traces for more details. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;34mf\"Executed layers up to: {executed_layers}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         ) from e\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "from transweather_model import DWConv\n",
    "\n",
    "model = DWConv()\n",
    "summary(model,\n",
    "        input_size=[(1,2048, 64), (64,), (64,)], \n",
    "        verbose=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"],\n",
    "        device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a405d0a8-ca43-491e-ab06-4c7dc557d9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 720, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "path = \"/home/ananth/TransWeather/dataset/allweather/input/0_rain.png\"\n",
    "img = cv2.imread(path)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abbbedec-199b-4ab1-88fd-d78cd8ba1cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 480, 720])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "image = torchvision.io.read_image(path)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adfe122-2d45-461e-a8bc-fc28d12b431f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b29c0-8958-4bc0-aec2-32507a7b94fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d91b3e-a10e-4f58-b6dc-ebdd30d7ea72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18069"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train_data_functions import TrainData\n",
    "\n",
    "train_dataset = TrainData(crop_size = [256, 256], train_data_dir = './allweather/',train_filename = 'allweather.txt')\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "100ab0f7-3de3-40dc-82ed-bdc1a9a0417e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from val_data_functions import ValData\n",
    "\n",
    "val_dataset = ValData(val_data_dir = './dataset/test_a/', val_filename = 'raindroptesta.txt')\n",
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a1f4be2-7e66-45b0-8f80-ac0665de92af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "423ac8ad-32ea-4166-95d4-970a7fda1334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'city_read_14216'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40b6e3c1-5cf9-49e4-a2fd-d5950703a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_path = \"./dataset/test_b/input/\"\n",
    "files = os.listdir(dataset_path)\n",
    "\n",
    "# files\n",
    "\n",
    "\n",
    "with open('./dataset/test_b/raindroptestb.txt', 'w') as file:\n",
    "    # Write each filename followed by a newline character\n",
    "    for filename in files:\n",
    "        file.write(dataset_path + filename + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0bfd3ca-99a2-40f4-b3ae-bef0e79f141f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from val_data_functions import ValData\n",
    "from utils2 import validation, validation_val\n",
    "from transweather_model import Transweather\n",
    "import sys\n",
    "\n",
    "net = Transweather()\n",
    "exp_name = \"Transweather_scratch_val_on_testset_a/\"\n",
    "\n",
    "try:\n",
    "    ckp_path = \"./{}best.pth\".format(exp_name)\n",
    "    ckp = torch.load(ckp_path)\n",
    "    net.load_state_dict(ckp)\n",
    "    print(\"Model loaded successfully\")\n",
    "except:\n",
    "    print(\"Unsuccessful in loading model\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5382e5-704a-4a4d-9dca-20e1a7053665",
   "metadata": {},
   "source": [
    "## Testing Transweather on raindrop test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "308a95c6-db22-4be5-8936-9966ff2de965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "--- Testing starts! ---\n",
      "val_psnr: 33.54, val_ssim: 0.9055\n",
      "validation time is 4.2633\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from val_data_functions import ValData\n",
    "from utils2 import validation, validation_val\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from transweather_model import Transweather\n",
    "import sys\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "\n",
    "val_batch_size = 1\n",
    "exp_name = \"Transweather_scratch_conv_tail_depthwise_conv/\"\n",
    "val_data_dir = './dataset/test_a/'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "val_filename = 'raindroptesta.txt'\n",
    "\n",
    "val_data_loader = DataLoader(ValData(val_data_dir,val_filename), batch_size=val_batch_size, shuffle=False)\n",
    "\n",
    "net = Transweather()\n",
    "\n",
    "\n",
    "# try:\n",
    "#     net.load_state_dict(torch.load('./{}/best.pth'.format(exp_name)))\n",
    "#     print(\"Model loaded successfully\")\n",
    "# except:\n",
    "#     print(\"Unsuccessful in loading model\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "try:\n",
    "    model_state_dict = torch.load('./{}/best.pth'.format(exp_name))\n",
    "    new_state_dict = {}\n",
    "\n",
    "    for key, value in model_state_dict.items():\n",
    "        new_key = key.replace(\"module.\",'')\n",
    "        new_state_dict[new_key] = value\n",
    "        \n",
    "    net.load_state_dict(new_state_dict)\n",
    "    print(\"Model loaded successfully\")\n",
    "except:\n",
    "    print(\"Unsuccessful in loading model\")\n",
    "    sys.exit(1)\n",
    "\n",
    "    \n",
    "net.to(device)\n",
    "net.eval()\n",
    "# if os.path.exists('./{}_results/{}/'.format(category,exp_name))==False:\n",
    "#     os.mkdir('./{}_results/{}/'.format(category,exp_name))\t\n",
    "#     os.mkdir('./{}_results/{}/rain/'.format(category,exp_name))\n",
    "print('--- Testing starts! ---')\n",
    "start_time = time.time()\n",
    "val_psnr, val_ssim = validation(net, val_data_loader, device, exp_name, save_tag=False)\n",
    "end_time = time.time() - start_time\n",
    "print('val_psnr: {0:.2f}, val_ssim: {1:.4f}'.format(val_psnr, val_ssim))\n",
    "print('validation time is {0:.4f}'.format(end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862f632-9d1e-4447-b297-794946f5c0c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Raindrop testB results\n",
    "## with Transweather_scratch_val_on_testset_a model\n",
    "* val_psnr: 29.48\n",
    "* val_ssim: 0.8606\n",
    "  \n",
    "\n",
    "## with Transweather_scratch_val_on_testset_b model\n",
    "* val_psnr: 29.89\n",
    "* val_ssim: 0.8603\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981924b0-e80e-4590-8fce-fe14c0556409",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Transweather on raindrop test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f88cf8-8c93-43f4-ac13-1ea08b59ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from utils2 import validation\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from transweather_model import Transweather\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a824bf6-02a8-4891-a816-403700d377a6",
   "metadata": {},
   "source": [
    "### Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87fa5945-9267-45ca-b395-69466031aa4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "\n",
    "# --- Validation/test dataset --- #\n",
    "class ValData(data.Dataset):\n",
    "    def __init__(self, val_input_filename ,val_gt_filename):\n",
    "        super().__init__()\n",
    "\n",
    "        with open(val_input_filename) as f:\n",
    "            contents = f.readlines()\n",
    "            input_names = [i.strip() for i in contents]\n",
    "        \n",
    "        with open(val_gt_filename) as f:\n",
    "            contents = f.readlines()\n",
    "            gt_names = [i.strip() for i in contents]\n",
    "            \n",
    "            \n",
    "        self.input_names = input_names\n",
    "        self.gt_names = gt_names\n",
    "\n",
    "    def get_images(self, index):\n",
    "        \n",
    "        input_name = self.input_names[index]\n",
    "        gt_name = self.gt_names[index]\n",
    "\n",
    "        input_img = Image.open(input_name)\n",
    "        gt_img = Image.open(gt_name)\n",
    "\n",
    "        # Resizing image in the multiple of 16\"\n",
    "        wd_new,ht_new = input_img.size\n",
    "        if ht_new>wd_new and ht_new>1024:\n",
    "            wd_new = int(np.ceil(wd_new*1024/ht_new))\n",
    "            ht_new = 1024\n",
    "        elif ht_new<=wd_new and wd_new>1024:\n",
    "            ht_new = int(np.ceil(ht_new*1024/wd_new))\n",
    "            wd_new = 1024\n",
    "        wd_new = int(16*np.ceil(wd_new/16.0))\n",
    "        ht_new = int(16*np.ceil(ht_new/16.0))\n",
    "        input_img = input_img.resize((wd_new,ht_new), Image.ANTIALIAS)\n",
    "        gt_img = gt_img.resize((wd_new, ht_new), Image.ANTIALIAS)\n",
    "\n",
    "        # --- Transform to tensor --- #\n",
    "        transform_input = Compose([ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        transform_gt = Compose([ToTensor()])\n",
    "        input_im = transform_input(input_img)\n",
    "        gt = transform_gt(gt_img)\n",
    "\n",
    "        return input_im, gt, input_name\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        res = self.get_images(index)\n",
    "        return res\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d9ed9-f815-4981-9abd-7ce98c5674b0",
   "metadata": {},
   "source": [
    "### Validating for AIWD6 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d5e2e3-7064-4e07-bb65-0e1b891b9129",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsuccessful in loading model\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m     new_state_dict[new_key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m---> 37\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_state_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1052\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Transweather:\n\tMissing key(s) in state_dict: \"convtail.dense_4.0.dwconv1.weight\", \"convtail.dense_4.0.dwconv1.bias\", \"convtail.dense_4.0.dwconv2.weight\", \"convtail.dense_4.0.dwconv2.bias\", \"convtail.dense_3.0.dwconv1.weight\", \"convtail.dense_3.0.dwconv1.bias\", \"convtail.dense_3.0.dwconv2.weight\", \"convtail.dense_3.0.dwconv2.bias\", \"convtail.dense_2.0.dwconv1.weight\", \"convtail.dense_2.0.dwconv1.bias\", \"convtail.dense_2.0.dwconv2.weight\", \"convtail.dense_2.0.dwconv2.bias\", \"convtail.dense_1.0.dwconv1.weight\", \"convtail.dense_1.0.dwconv1.bias\", \"convtail.dense_1.0.dwconv2.weight\", \"convtail.dense_1.0.dwconv2.bias\". \n\tUnexpected key(s) in state_dict: \"convtail.dense_4.0.conv1.conv2d.weight\", \"convtail.dense_4.0.conv1.conv2d.bias\", \"convtail.dense_4.0.conv2.conv2d.weight\", \"convtail.dense_4.0.conv2.conv2d.bias\", \"convtail.dense_3.0.conv1.conv2d.weight\", \"convtail.dense_3.0.conv1.conv2d.bias\", \"convtail.dense_3.0.conv2.conv2d.weight\", \"convtail.dense_3.0.conv2.conv2d.bias\", \"convtail.dense_2.0.conv1.conv2d.weight\", \"convtail.dense_2.0.conv1.conv2d.bias\", \"convtail.dense_2.0.conv2.conv2d.weight\", \"convtail.dense_2.0.conv2.conv2d.bias\", \"convtail.dense_1.0.conv1.conv2d.weight\", \"convtail.dense_1.0.conv1.conv2d.bias\", \"convtail.dense_1.0.conv2.conv2d.weight\", \"convtail.dense_1.0.conv2.conv2d.bias\". ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[6], line 41\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsuccessful in loading model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2092\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2090\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2091\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2092\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2093\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2095\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2096\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   2097\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   2098\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py:644\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    637\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py:511\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    508\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    509\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    510\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 511\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py:1310\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m tb\n\u001b[0;32m-> 1310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py:1199\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1196\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py:1052\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1045\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1050\u001b[0m ):\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py:953\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    951\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(etype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m    952\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 953\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    954\u001b[0m )\n\u001b[1;32m    956\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    957\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py:1021\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1021\u001b[0m         source_file \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetsourcefile(\u001b[43metb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1022\u001b[0m         lines, first \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetsourcelines(etb\u001b[38;5;241m.\u001b[39mtb_frame)\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "val_batch_size = 32\n",
    "exp_name = \"Transweather_scratch_val_on_testset_a\"\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "meta_path = \"/home/ananth/TransWeather/dataset/AIWD6/meta/\"\n",
    "meta_files = os.listdir(meta_path) \n",
    "\n",
    "for file in meta_files:\n",
    "    \n",
    "    val_input_filename = f'./dataset/AIWD6/meta/{file}/input.txt'\n",
    "    val_gt_filename = f'./dataset/AIWD6/meta/{file}/gt.txt'\n",
    "    \n",
    "    \n",
    "    dataset = ValData(val_input_filename,val_gt_filename)\n",
    "    val_data_loader = DataLoader(dataset, batch_size=val_batch_size, \n",
    "                                 shuffle=False, num_workers = 8, pin_memory = True)\n",
    "    \n",
    "    net = Transweather()\n",
    "    net.to(device)\n",
    "    \n",
    "    # try:\n",
    "    #     net.load_state_dict(torch.load('./{}/latest.pth'.format(exp_name)))\n",
    "    #     print(\"Model loaded successfully\")\n",
    "    # except:\n",
    "    #     print(\"Unsuccessful in loading model\")\n",
    "    #     sys.exit(1)\n",
    "    try:\n",
    "        model_state_dict = torch.load('./{}/best.pth'.format(exp_name))\n",
    "        new_state_dict = {}\n",
    "    \n",
    "        for key, value in model_state_dict.items():\n",
    "            new_key = key.replace(\"module.\",'')\n",
    "            new_state_dict[new_key] = value\n",
    "            \n",
    "        net.load_state_dict(new_state_dict)\n",
    "        print(\"Model loaded successfully\")\n",
    "    except:\n",
    "        print(\"Unsuccessful in loading model\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    \n",
    "    net.eval()\n",
    "    # if os.path.exists('./{}_results/{}/'.format(category,exp_name))==False:\n",
    "    #     os.mkdir('./{}_results/{}/'.format(category,exp_name))\t\n",
    "    #     os.mkdir('./{}_results/{}/rain/'.format(category,exp_name))\n",
    "    print('--- Testing starts! ---')\n",
    "    start_time = time.time()\n",
    "    val_psnr, val_ssim = validation(net, val_data_loader, device, exp_name, save_tag=False)\n",
    "    end_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"{file}: Images extracted :\", len(dataset))\n",
    "    \n",
    "    print('val_psnr: {0:.2f}, val_ssim: {1:.4f}'.format(val_psnr, val_ssim))\n",
    "    print('validation time is {0:.4f}'.format(end_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6485552a-aa53-4fc6-b319-607d84cffbe7",
   "metadata": {},
   "source": [
    "### Validating for Snow100k-L dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a5e5de-3311-49fb-8787-2e693415bf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "--- Testing starts! ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_812607/2275400147.py:41: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  input_img = input_img.resize((wd_new,ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:41: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  input_img = input_img.resize((wd_new,ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:41: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  input_img = input_img.resize((wd_new,ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:41: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  input_img = input_img.resize((wd_new,ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:41: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  input_img = input_img.resize((wd_new,ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:41: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  input_img = input_img.resize((wd_new,ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:41: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  input_img = input_img.resize((wd_new,ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:42: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  gt_img = gt_img.resize((wd_new, ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:42: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  gt_img = gt_img.resize((wd_new, ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:42: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  gt_img = gt_img.resize((wd_new, ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:42: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  gt_img = gt_img.resize((wd_new, ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:42: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  gt_img = gt_img.resize((wd_new, ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:42: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  gt_img = gt_img.resize((wd_new, ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:42: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  gt_img = gt_img.resize((wd_new, ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:41: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  input_img = input_img.resize((wd_new,ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_812607/2275400147.py:42: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  gt_img = gt_img.resize((wd_new, ht_new), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_psnr: 33.39, val_ssim: 0.8897\n",
      "validation time is 883.5207\n"
     ]
    }
   ],
   "source": [
    "val_batch_size = 1\n",
    "exp_name = \"Transweather_scratch_enc_depth_3_3_2_2\"\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    \n",
    "val_input_filename = './dataset/Snow100K-testset/media/jdway/GameSSD/overlapping/test/Snow100K-L/synthetic.txt'\n",
    "val_gt_filename = './dataset/Snow100K-testset/media/jdway/GameSSD/overlapping/test/Snow100K-L/gt.txt'\n",
    "\n",
    "\n",
    "dataset = ValData(val_input_filename,val_gt_filename)\n",
    "val_data_loader = DataLoader(dataset, batch_size=val_batch_size, \n",
    "                             shuffle=False, num_workers = 8, pin_memory = True)\n",
    "\n",
    "net = Transweather()\n",
    "net.to(device)\n",
    "\n",
    "# try:\n",
    "#     net.load_state_dict(torch.load('./{}/best.pth'.format(exp_name)))\n",
    "#     print(\"Model loaded successfully\")\n",
    "# except:\n",
    "#     print(\"Unsuccessful in loading model\")\n",
    "#     sys.exit(1)\n",
    "try:\n",
    "    model_state_dict = torch.load('./{}/best.pth'.format(exp_name))\n",
    "    new_state_dict = {}\n",
    "    \n",
    "    for key, value in model_state_dict.items():\n",
    "        new_key = key.replace(\"module.\",'')\n",
    "        new_state_dict[new_key] = value\n",
    "        \n",
    "    net.load_state_dict(new_state_dict)\n",
    "    print(\"Model loaded successfully\")\n",
    "except:\n",
    "    print(\"Unsuccessful in loading model\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "print('--- Testing starts! ---')\n",
    "start_time = time.time()\n",
    "val_psnr, val_ssim = validation(net, val_data_loader, device, exp_name, save_tag=False)\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print('val_psnr: {0:.2f}, val_ssim: {1:.4f}'.format(val_psnr, val_ssim))\n",
    "print('validation time is {0:.4f}'.format(end_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325cdb28-886a-4126-995f-77005dccdb49",
   "metadata": {},
   "source": [
    "# Results on Snowtest 100k-L\n",
    "## Scratch_a\n",
    "* Val PSNR = 33.40\n",
    "* Val SSIM = 0.8901\n",
    "## Scratch_b\n",
    "* Val PSNR = 33.61\n",
    "* Val SSIM = 0.8889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c6a6e86-ca11-4f2a-9b81-eecfb0377aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torchvision\n",
    "img_name = \"./dataset/AIWD6/Rainy_to_Cloudy/0 to 293/Image1.png\"\n",
    "img = torchvision.io.read_image(img_name)\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9ccec9d-30eb-4976-880a-86ae40e78a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalized_image = img.float() / 255.0\n",
    "# img_normalized = normalize_image_tensor(img)\n",
    "torchvision.utils.save_image(normalized_image, \"./demo_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b88a5542-7d83-45c2-9dc9-75a9eddbca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate input.txt and gt.txt files for each image from img0 to img9 for each subfolder\n",
    "import os\n",
    "\n",
    "main_folder = \"./dataset/AIWD6/Sunny_to_Rainy/\"\n",
    "\n",
    "subfolders = os.listdir(main_folder)\n",
    "subfolders.sort()\n",
    "\n",
    "for i in range(0, 10):  # For each image from img0 to img9\n",
    "    input_file = open(f'./dataset/AIWD6/meta/Sunny_to_Rainy/input{i}.txt', 'w')\n",
    "    gt_file = open('./dataset/AIWD6/meta/Sunny_to_Rainy/gt.txt', 'w')\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        if os.path.exists(os.path.join(main_folder, subfolder, f'{i}.png')):\n",
    "            img_path = os.path.join(main_folder, subfolder, f'{i}.png')\n",
    "            gt_path = os.path.join(main_folder, subfolder, 'Image1.png')\n",
    "\n",
    "        input_file.write(img_path + '\\n')\n",
    "        gt_file.write(gt_path + '\\n')\n",
    "\n",
    "    input_file.close()  \n",
    "    gt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21d122-a82e-4ca4-9292-96303deae895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1005741-d6aa-488e-893b-16edacdb9f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare meta for AIWD6 data\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "dataset_path = \"./dataset/AIWD6/Rainy_to_Sunny/\"\n",
    "folders = os.listdir(dataset_path)\n",
    "folders.sort()\n",
    "\n",
    "for folder in folders:\n",
    "    img_list = os.listdir(dataset_path+folder)\n",
    "    img_list.sort()  # to remove interpolated image from list \n",
    "    \n",
    "    if len(img_list)!=13: # some folder do not have 13 images\n",
    "        continue\n",
    "    img_list = img_list[:-1]\n",
    "    \n",
    "    # store gt image and Image1 or Image2 dependong on folder\n",
    "    gt_img = img_list[-1]\n",
    "    # temp_img = img_list[-1]\n",
    "    \n",
    "    # remove gt and add that Image1 or Image2\n",
    "    img_list = img_list[:-1]\n",
    "    # img_list.append(temp_img)\n",
    "    \n",
    "    with open(\"./dataset/AIWD6/meta/Rainy_to_Sunny/input.txt\", 'a') as file:\n",
    "        for img_name in img_list:\n",
    "            file.write(dataset_path + folder + '/' + img_name + '\\n')\n",
    "            \n",
    "    with open(\"./dataset/AIWD6/meta/Rainy_to_Sunny/gt.txt\", 'a') as file:\n",
    "        for _ in range(len(img_list)):\n",
    "            file.write(dataset_path + folder + '/' + gt_img + '\\n')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853a5010-1374-48a9-af6c-1af7226b7db1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare meta for raindrop SnowTest100k-L data\n",
    "\n",
    "import os\n",
    "dataset_path = \"./dataset/Snow100K-testset/media/jdway/GameSSD/overlapping/test/Snow100K-L/synthetic/\"\n",
    "files = os.listdir(dataset_path)\n",
    "files.sort()\n",
    "\n",
    "input_filename = \"synthetic.txt\"\n",
    "with open('./dataset/Snow100K-testset/media/jdway/GameSSD/overlapping/test/Snow100K-L/' + input_filename, 'w') as file:\n",
    "    # Write each filename followed by a newline character\n",
    "    for filename in files:\n",
    "        file.write(dataset_path + filename + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "dataset_path = \"./dataset/Snow100K-testset/media/jdway/GameSSD/overlapping/test/Snow100K-L/gt/\"\n",
    "files = os.listdir(dataset_path)\n",
    "files.sort()\n",
    "gt_filename = \"gt.txt\"\n",
    "with open('./dataset/Snow100K-testset/media/jdway/GameSSD/overlapping/test/Snow100K-L/' + gt_filename, 'w') as file:\n",
    "    # Write each filename followed by a newline character\n",
    "    for filename in files:\n",
    "        file.write(dataset_path + filename + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e277ea1-382c-4177-943d-67654d2082c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "import cv2\n",
    "\n",
    "img_1_path = \"./dataset/AIWD6/Rainy_to_Cloudy/0 to 293/Image1.png\"\n",
    "im1 = torchvision.io.read_image(img_1_path)\n",
    "\n",
    "img_2_path = \"./demo_image.png\"\n",
    "im2 = torchvision.io.read_image(img_2_path)\n",
    "\n",
    "im1 = im1.reshape(im1.shape[1],im1.shape[2],3)\n",
    "im2 = im2.reshape(im2.shape[1],im2.shape[2],3)\n",
    "\n",
    "im1 = im1.numpy()\n",
    "im2 = im2.numpy()\n",
    "\n",
    "im1_y = cv2.cvtColor(im1, cv2.COLOR_BGR2YCR_CB)[:, :, 0]\n",
    "im2_y = cv2.cvtColor(im2, cv2.COLOR_BGR2YCR_CB)[:, :, 0]\n",
    "\n",
    "\n",
    "ans = structural_similarity(im1_y, im2_y, data_range=1, multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71c3512-9146-416e-8168-a6f573b039fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52aac89b-10fc-4cc8-8fa9-084e9868cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img_1_path = \"./dataset/AIWD6/Rainy_to_Cloudy/0 to 293/0.png\"\n",
    "im1 = Image.open(img_1_path)\n",
    "# im1 = im1.unsqueeze(dim=0)\n",
    "\n",
    "transform_input = Compose([ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "im1 = transform_input(im1).unsqueeze(dim=0).to(device)\n",
    "output = net(im1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4c1ea-d9d4-4c11-a2e9-7712f7a88d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a2ae27-8bcf-42d0-b9eb-ab691754f115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "662e60a5-06ae-48ab-a899-f02ec5d311b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning snow100K-L dataset\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "datapath = \"./dataset/Snow100K-testset/media/jdway/GameSSD/overlapping/test/Snow100K-L/synthetic/\"\n",
    "files = os.listdir(datapath)\n",
    "\n",
    "\n",
    "input_folder = \"./dataset/Snow100K-testset/media/jdway/GameSSD/overlapping/test/Snow100K-L/synthetic/\"\n",
    "gt_folder = \"./dataset/Snow100K-testset/media/jdway/GameSSD/overlapping/test/Snow100K-L/gt/\"\n",
    "\n",
    "bad_imgs = []\n",
    "\n",
    "for file in files:\n",
    "    img_path = input_folder + file\n",
    "    gt_path = gt_folder + file\n",
    "\n",
    "    img = torchvision.io.read_image(img_path)\n",
    "    gt = torchvision.io.read_image(gt_path)\n",
    "\n",
    "    if(img.shape != gt.shape):\n",
    "        bad_imgs.append(file)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e413b4e3-71f5-4003-a870-87ce6822979b",
   "metadata": {},
   "source": [
    "## Function take input and gt and compute output image and PSNR and SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3559df4-40d3-4cf8-a9be-1540dc17f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_814689/2352379414.py:39: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  input_img = input_img.resize((wd_new,ht_new), Image.ANTIALIAS)\n",
      "/tmp/ipykernel_814689/2352379414.py:40: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  gt_img = gt_img.resize((wd_new, ht_new), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "--- Evaluation starts! ---\n",
      "Input image torch.Size([3, 432, 640])\n",
      "predicted Image torch.Size([3, 432, 640])\n",
      "Ground Truth Image torch.Size([3, 432, 640])\n",
      "torch.Size([3, 432, 640])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Normalize, ToTensor, Compose\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from val_data_functions import ValData\n",
    "from utils2 import validation, validation_val\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from transweather_model import Transweather\n",
    "import sys\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "inp_image_path = \"./dataset/realistic/sidewalk winter -grayscale -gray_00440.jpg\"\n",
    "gt_image_path = \"./dataset/AIWD6/Rainy_to_Cloudy/27 to 320/Image2.png\"\n",
    "\n",
    "\n",
    "input_img = Image.open(inp_image_path)\n",
    "gt_img = Image.open(gt_image_path)\n",
    "\n",
    "# Resizing image in the multiple of 16\"\n",
    "wd_new,ht_new = input_img.size\n",
    "if ht_new>wd_new and ht_new>1024:\n",
    "    wd_new = int(np.ceil(wd_new*1024/ht_new))\n",
    "    ht_new = 1024\n",
    "elif ht_new<=wd_new and wd_new>1024:\n",
    "    ht_new = int(np.ceil(ht_new*1024/wd_new))\n",
    "    wd_new = 1024\n",
    "wd_new = int(16*np.ceil(wd_new/16.0))\n",
    "ht_new = int(16*np.ceil(ht_new/16.0))\n",
    "input_img = input_img.resize((wd_new,ht_new), Image.ANTIALIAS)\n",
    "gt_img = gt_img.resize((wd_new, ht_new), Image.ANTIALIAS)\n",
    "\n",
    "# --- Transform to tensor --- #\n",
    "transform_input = Compose([ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "transform_gt = Compose([ToTensor()])\n",
    "input_im = transform_input(input_img).unsqueeze(dim=0).to(device)\n",
    "gt = transform_gt(gt_img)\n",
    "\n",
    "\n",
    "\n",
    "exp_name = \"Transweather_scratch_conv_tail_depthwise_conv/\"\n",
    "net = Transweather()\n",
    "\n",
    "\n",
    "# try:\n",
    "#     net.load_state_dict(torch.load('./{}/best.pth'.format(exp_name)))\n",
    "#     print(\"Model loaded successfully\")\n",
    "# except:\n",
    "#     print(\"Unsuccessful in loading model\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "try:\n",
    "    model_state_dict = torch.load('./{}/best.pth'.format(exp_name))\n",
    "    new_state_dict = {}\n",
    "\n",
    "    for key, value in model_state_dict.items():\n",
    "        new_key = key.replace(\"module.\",'')\n",
    "        new_state_dict[new_key] = value\n",
    "        \n",
    "    net.load_state_dict(new_state_dict)\n",
    "    print(\"Model loaded successfully\")\n",
    "except:\n",
    "    print(\"Unsuccessful in loading model\")\n",
    "    sys.exit(1)\n",
    "\n",
    "    \n",
    "net.to(device)\n",
    "net.eval()\n",
    "\n",
    "print('--- Evaluation starts! ---')\n",
    "pred_image = net(input_im)\n",
    "\n",
    "\n",
    "input_im = input_im.squeeze()\n",
    "pred_image = pred_image.squeeze()\n",
    "\n",
    "print(\"Input image\", input_im.shape)\n",
    "print(\"predicted Image\", pred_image.shape)\n",
    "print(\"Ground Truth Image\", gt.shape)\n",
    "\n",
    "save_image = pred_image.detach().cpu().reshape(3, pred_image.shape[1], pred_image.shape[2])\n",
    "# gt = gt.cpu().numpy().reshape(gt.shape[1], gt.shape[2], 3)\n",
    "# pred_image = pred_image.detach().cpu().numpy().reshape(pred_image.shape[1], pred_image.shape[2], 3)\n",
    "\n",
    "# im1_y = cv2.cvtColor(gt, cv2.COLOR_BGR2YCR_CB)[:, :, 0] \n",
    "# im2_y = cv2.cvtColor(pred_image, cv2.COLOR_BGR2YCR_CB)[:, :, 0] \n",
    "\n",
    "\n",
    "# ssim = structural_similarity(im1_y, im2_y, data_range=1, multichannel=True)\n",
    "# psnr = peak_signal_noise_ratio(im1_y, im2_y)\n",
    "\n",
    "# print(\"\\nSSIM\", ssim)\n",
    "# print(\"PSNR\", psnr)\n",
    "\n",
    "print(save_image.shape)\n",
    "torchvision.utils.save_image(save_image, \"./output_image_conv.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb312874-7e22-41fc-b048-fe2afa9b2735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
